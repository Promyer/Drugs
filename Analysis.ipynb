{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Детекция названий препаратов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Положите данные в папку с ноутбуком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "#import time\n",
    "import re\n",
    "#import nltk\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "import _pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('clitical_trials_100000.tsv', delimiter='\\t', encoding='utf-8').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Возвращает названия препаратов из строки таблицы\n",
    "def words_by_coord (inform):\n",
    "    coords = re.findall(\"(\\d+, \\d+)\", inform[0][1:-1])\n",
    "    drugs_coord = []\n",
    "    names = []\n",
    "    for i in coords:\n",
    "        drugs_coord.append(re.split(\", \", i))\n",
    "    for k in drugs_coord:\n",
    "        names.append(inform[1][int(k[0]):int(k[1])])\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Возвращает список всех названий препаратов из таблицы\n",
    "def extract_drugs(_data):\n",
    "    _buf = []\n",
    "    for i in _data:\n",
    "        _buf += words_by_coord(i)\n",
    "    return _buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(sentence):\n",
    "    return list(filter(lambda x: x != ',', word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подсчет количества слов\n",
    "def word_counter (_data):\n",
    "    _num = 0\n",
    "    for i in _data:\n",
    "        s = 0\n",
    "        _tkzed = word_tokenize(i[1])\n",
    "        for q in _tkzed:\n",
    "            if (len(q) <= 3):\n",
    "                s +=1\n",
    "        _num += len(_tkzed) - s\n",
    "    return _num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразование таблицы в новую, где каждая строка - одно слово, номер его текста и булево значение препарат - не прпеарат\n",
    "def create_data(_data, _len):\n",
    "    drug_array = np.empty(( _len), dtype=bool)\n",
    "    sentence_array = np.empty((_len), dtype=int)\n",
    "    word_array = np.empty((_len), dtype='<U16')\n",
    "    counter = 0\n",
    "    for i, row in enumerate(_data):\n",
    "        drugs_in_t = set(extract_drugs([row]))\n",
    "        for word in word_tokenize(row[1]):\n",
    "            if (len(word) > 3):\n",
    "                sentence_array[counter] = i\n",
    "                word_array[counter] = word\n",
    "                drug_array[counter] = not drugs_in_t.isdisjoint(set([word]))\n",
    "                counter += 1\n",
    "    return pd.DataFrame({'word':word_array, 'sentence':sentence_array, 'drug':drug_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание таблицы слово - метка\n",
    "def create_data_for_FT(_data, _len):\n",
    "    drug_array = np.empty(( _len), dtype=bool)\n",
    "    word_array = np.empty((_len), dtype='<U16')\n",
    "    counter = 0\n",
    "    for row in _data:\n",
    "        drugs_in_t = set(extract_drugs([row]))\n",
    "        for word in word_tokenize(row[1]):\n",
    "            if (len(word) > 3):\n",
    "                word_array[counter] = word\n",
    "                drug_array[counter] = not drugs_in_t.isdisjoint(set([word]))\n",
    "                counter += 1\n",
    "    return pd.DataFrame({'word':word_array, 'drug':drug_array})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим список всех известных препаратов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dalotuzumab',\n",
       " 'len',\n",
       " '6th',\n",
       " 'lipopeptide',\n",
       " 'double',\n",
       " 'suicide',\n",
       " 'z-vad',\n",
       " 'motif',\n",
       " 'dhfr',\n",
       " 'tnf-alpha-dependent-inos-independent',\n",
       " 'lhrha',\n",
       " 'enhance',\n",
       " 'primary',\n",
       " 'cgy',\n",
       " 'anti-cancer',\n",
       " 'egfr-tyrosine-kinase',\n",
       " 'terminal',\n",
       " 'bct',\n",
       " 'tag',\n",
       " 'dox',\n",
       " 'urals',\n",
       " 'premedication',\n",
       " 'estramustine',\n",
       " 'r-cvp',\n",
       " 'live-donor',\n",
       " 'tomodirect',\n",
       " 'duel',\n",
       " 'kilobase',\n",
       " 'radioimmunchemotherapy',\n",
       " '26s',\n",
       " 'nsaid',\n",
       " 'bid',\n",
       " 'folic',\n",
       " 'physiokinesic',\n",
       " 'nras',\n",
       " 'cdh1',\n",
       " 'ril-21',\n",
       " 'corporeal',\n",
       " 'gamma-secreting',\n",
       " 'ponatinib',\n",
       " 'prescribe',\n",
       " 'non-cross-resistant',\n",
       " 'lenvantinib',\n",
       " 'alfa-2b',\n",
       " 'wbrt',\n",
       " 'ang',\n",
       " 'target-dependent',\n",
       " 'mmc',\n",
       " '51',\n",
       " 'alkylator-based',\n",
       " 'cddp-containing',\n",
       " 'c-myc',\n",
       " 'cornea',\n",
       " 'trf',\n",
       " '-booster',\n",
       " 'well-described',\n",
       " '?-2b',\n",
       " 'convenient',\n",
       " 'anti-id',\n",
       " 'varicella',\n",
       " 'anti-androgen',\n",
       " 'calpeptin',\n",
       " 'fibroblasts.this',\n",
       " 'das-driven',\n",
       " 'gcv',\n",
       " 'mapk-activating',\n",
       " 'intracoronary',\n",
       " 'clodronate',\n",
       " 'el4-b7.1',\n",
       " 'soak',\n",
       " 'brathytherapy',\n",
       " 'mir-21-3p',\n",
       " 'iort',\n",
       " 'monophosphoryl-lipid',\n",
       " 'ibd',\n",
       " '4666',\n",
       " 'glucose-lowering',\n",
       " 'frap',\n",
       " 'single-',\n",
       " 'pleural',\n",
       " 'arm',\n",
       " 'transplant',\n",
       " '17-aag',\n",
       " 'prot',\n",
       " 'tgfbr2',\n",
       " 'non-adjuvanted',\n",
       " 'isotretinoin',\n",
       " 'pegaptanib',\n",
       " 'piperacillin',\n",
       " 'bicyclic',\n",
       " 'ghrelin+pi3k',\n",
       " 'actinic',\n",
       " 'v-fnd',\n",
       " 'hla-a2-restricted',\n",
       " 'glial',\n",
       " 'comprehensive',\n",
       " 'hormone-based',\n",
       " 'derive',\n",
       " 'chemoembolization',\n",
       " 'ifn-?',\n",
       " 'harvest',\n",
       " 'yag',\n",
       " 'bind',\n",
       " 'nipp',\n",
       " 'non-bevacizumab-containing',\n",
       " 'beta-blocker',\n",
       " 'hbv-active',\n",
       " 'free',\n",
       " 'vtx-2337',\n",
       " '-selective',\n",
       " '44',\n",
       " 'tegaserod',\n",
       " 'intracerebral',\n",
       " 'triple-negative',\n",
       " 'tocotrienol',\n",
       " 'clathrin-specific',\n",
       " 'rapamycin',\n",
       " 'pre-erythrocytic',\n",
       " 'p.',\n",
       " 'bmp2',\n",
       " 'ant',\n",
       " 'isis',\n",
       " 'equipotent',\n",
       " 'liposomal',\n",
       " 'gram-positive',\n",
       " 'cytokine-secreting',\n",
       " 'adrc-enriched',\n",
       " 'methylaminolevulinate',\n",
       " 'isogenic',\n",
       " 'equivalent',\n",
       " 'r-based',\n",
       " 'rare',\n",
       " 'radiodynamic',\n",
       " 'post-bone',\n",
       " 'erk1',\n",
       " 'haemopoietic',\n",
       " 'grid',\n",
       " 'mono',\n",
       " 'stta',\n",
       " 'steroidogenesis',\n",
       " 'type-ii',\n",
       " 'dc-cik',\n",
       " 'original',\n",
       " 'eph-dc',\n",
       " 'activator',\n",
       " 'molecule',\n",
       " '888',\n",
       " 'electrolyte',\n",
       " 'aggregation',\n",
       " 'erlotinib',\n",
       " 'beta-adrenoblocking',\n",
       " 'sexotherapy',\n",
       " 'first-course',\n",
       " 'dehydrogenase',\n",
       " 'phosphorothioate',\n",
       " 'kinase-3',\n",
       " 'hla-a*0201-restricted',\n",
       " 'nf-?b-',\n",
       " 'prepegvisomant',\n",
       " 'insomnia',\n",
       " 'ethidium',\n",
       " 'mntmpyp',\n",
       " 'angiokinase',\n",
       " 'label',\n",
       " 'non-adenosine',\n",
       " 'cell-mediated',\n",
       " 'factor-1',\n",
       " 'spot',\n",
       " 'granulocyte-macrophage',\n",
       " 'ifn-alpha2b',\n",
       " 'ubiquitin-proteasome-dependent',\n",
       " 'dc-targeting',\n",
       " 'camkii-specific',\n",
       " 'hypercapnotherapy',\n",
       " 'glutamate-cysteine',\n",
       " 'language',\n",
       " 'chop',\n",
       " 'psa',\n",
       " 'lfp',\n",
       " 'pharmacokinetics',\n",
       " 'alecensa',\n",
       " 'l-citrulline',\n",
       " 'emactuzumab',\n",
       " 'conventional-dose',\n",
       " 'mmp-9',\n",
       " 'benefit',\n",
       " 'health',\n",
       " 'hit',\n",
       " 'passively',\n",
       " 'inhibitor-based',\n",
       " '0.5',\n",
       " 'filgotinib',\n",
       " 'uncontrollable',\n",
       " 'art',\n",
       " '36',\n",
       " 'especially',\n",
       " 'out-patient',\n",
       " 'nhp',\n",
       " 'sphincter-saving',\n",
       " 'status',\n",
       " 'breast-sparing',\n",
       " 'immune',\n",
       " 'anticholinergic',\n",
       " 'catholic',\n",
       " 'syk',\n",
       " 'non-pharmcological',\n",
       " 'controversial',\n",
       " 'insulinoma',\n",
       " 'rtki',\n",
       " 'establish',\n",
       " 'capacity',\n",
       " 'antiproliferative',\n",
       " 'triple-drug',\n",
       " 't-helper',\n",
       " 'applicator-guided',\n",
       " 'survey',\n",
       " 'physiokinesistherapy',\n",
       " 'mdt',\n",
       " 'sr-b1',\n",
       " 'chitosan',\n",
       " 'brm',\n",
       " 'calicineurin',\n",
       " 'macarthur',\n",
       " 'multi',\n",
       " 'mpnst',\n",
       " 'hsct',\n",
       " 'ctl',\n",
       " 'cryosurgery',\n",
       " 'bifocal',\n",
       " 'allospecific',\n",
       " 'patient-specific',\n",
       " '-type',\n",
       " 'furosemide',\n",
       " 'sc236',\n",
       " 'endocrinotherapy',\n",
       " 'oncoprotein-containing',\n",
       " 'kurative',\n",
       " 'ant2',\n",
       " 't-type',\n",
       " 'crad-gene',\n",
       " 'cetuximab-irinotecan',\n",
       " 'hdac2-specific',\n",
       " 's-phase',\n",
       " 'v-atpase',\n",
       " 'low-risk',\n",
       " 'naturally',\n",
       " 'aluminium-containing',\n",
       " 'margin',\n",
       " 'psycho-oncological',\n",
       " 'alendronate',\n",
       " 'post-chemotherapy',\n",
       " 'neratinib',\n",
       " 'anti-h',\n",
       " 'kdm1',\n",
       " 'pld-carbo',\n",
       " 'taxotere',\n",
       " 'valganciclovir',\n",
       " 'biopsie',\n",
       " 'statusand',\n",
       " 'dimerization',\n",
       " 'prostatic',\n",
       " 'dd',\n",
       " 'hydrotherapy',\n",
       " 'muc1',\n",
       " 'initially',\n",
       " 'alisertib',\n",
       " 'oral',\n",
       " 'mmr',\n",
       " 'hif1?',\n",
       " 'as03-adjuvanted',\n",
       " 'all-type',\n",
       " 'fp',\n",
       " 'x-ray',\n",
       " 'hiv-to-hiv',\n",
       " 'plcgamma',\n",
       " 'stag',\n",
       " 'subtype',\n",
       " 'hucb',\n",
       " 'trail-alone',\n",
       " 'annual',\n",
       " 'pandeacetylase',\n",
       " 'microwave',\n",
       " 'copp',\n",
       " 'similar',\n",
       " 'relaxation',\n",
       " 'recurrence',\n",
       " 'gabaergic',\n",
       " 'hand',\n",
       " 'mai',\n",
       " 'register',\n",
       " 'ptld',\n",
       " \"'immune\",\n",
       " 'monocytogenes-based',\n",
       " 'minipelvis',\n",
       " 'pre-study',\n",
       " 'radioiodinate',\n",
       " 'factor-targeted',\n",
       " 'cdk5',\n",
       " 'i',\n",
       " 'mitoxantrone',\n",
       " 'vocimagene',\n",
       " 'mmp-3-driven',\n",
       " 'neutralize',\n",
       " 'histocompatibility',\n",
       " 'beacoppesc',\n",
       " 'lu-dkfz-psma-617',\n",
       " 'clivatuzumab',\n",
       " 'serotonin',\n",
       " '93',\n",
       " 'agvhd',\n",
       " 'ifosfamide',\n",
       " 'hypoxytherapy',\n",
       " 'non-ansamycin',\n",
       " 'nanoirradiation',\n",
       " 'pemetrexe',\n",
       " 'p.o',\n",
       " 'structure-based',\n",
       " 'immunoprevention',\n",
       " 'high-risk',\n",
       " 'capgem',\n",
       " 'tumour-specific',\n",
       " 'rbz',\n",
       " 'gemcitabine-erlotinib',\n",
       " 'personalize',\n",
       " 'bell',\n",
       " 'antihormonal',\n",
       " 'c-src',\n",
       " 'male',\n",
       " 'time-consuming',\n",
       " 'triweekly',\n",
       " 'gaa-dc',\n",
       " 'everolimus',\n",
       " 'phagocytosis',\n",
       " 'ifx',\n",
       " 'allocate',\n",
       " 'antituberculosis',\n",
       " 'mesotherapy',\n",
       " 'anthracycline-cyclophosphamide',\n",
       " 'intrathecal',\n",
       " '-chop',\n",
       " 'attractive',\n",
       " 'whose',\n",
       " 'photohemotherapy',\n",
       " 'ondansetron',\n",
       " 'carbon',\n",
       " 'mek1',\n",
       " 'multivisceral',\n",
       " 'staphylococcal',\n",
       " 'myc',\n",
       " 'pre-bmt',\n",
       " 'lipase',\n",
       " 'endothelial',\n",
       " 'mtor-based',\n",
       " 'biopsy',\n",
       " 'life-supporting',\n",
       " 'hla-matched',\n",
       " 'radio-',\n",
       " 'gemcitabine-docetaxel',\n",
       " 'anti-aromatase',\n",
       " 'physiokinesitherapy',\n",
       " 'tocilizumab',\n",
       " 'non-pharmacologic',\n",
       " 'autoimplantation',\n",
       " 'ade1-lmppoly',\n",
       " 'invasive',\n",
       " 'an-tiangiogenic',\n",
       " 'pafr',\n",
       " 'step-down',\n",
       " 'il-17a',\n",
       " 'real-time',\n",
       " 'smad3-binding',\n",
       " 'radiationtherapy',\n",
       " 'p53-slp?',\n",
       " 'eoc',\n",
       " 'two',\n",
       " 'antileukemia',\n",
       " 'trypsin',\n",
       " 'vp16',\n",
       " 'single-session',\n",
       " 'aglatimagene',\n",
       " 'dimaleate',\n",
       " 'tpmt',\n",
       " 't2',\n",
       " 'decoy',\n",
       " '130',\n",
       " 'potential',\n",
       " 'cg7870',\n",
       " 'target-specific',\n",
       " 'combotm',\n",
       " 'mantle',\n",
       " 'ifnbeta-1a',\n",
       " 'nb-uvb',\n",
       " 'significantly',\n",
       " 'firmagon',\n",
       " 'ng-monomethyl-l-arginine',\n",
       " 'mylotarg',\n",
       " 'ddk',\n",
       " 'huvecs-ok432',\n",
       " 'timing',\n",
       " 'bezlotoxumab',\n",
       " 'adherent',\n",
       " 'ly6k-177',\n",
       " 'best-evaluated',\n",
       " 'mirna-based',\n",
       " 'divide',\n",
       " '842',\n",
       " 'adenovirotherapy',\n",
       " 'prostvac',\n",
       " 'aqp1',\n",
       " 'respiratory',\n",
       " 'microenvironment-tailored',\n",
       " 'ganetespib',\n",
       " 'olanzapin',\n",
       " 'various',\n",
       " 'mean',\n",
       " 'primordial',\n",
       " 'hpc',\n",
       " 'multiple',\n",
       " 'pateclizumab',\n",
       " 'anti-factor',\n",
       " 'in-situ',\n",
       " 'dcp',\n",
       " 'p-akt',\n",
       " 'comorbidity',\n",
       " 'cytosar-u',\n",
       " 'ipl',\n",
       " 'dapsone',\n",
       " 'care',\n",
       " 'postoperative',\n",
       " 'stimulation',\n",
       " 'nelfinavir',\n",
       " 'splint',\n",
       " 'prechemoradiotherapy',\n",
       " 'salmonella',\n",
       " 'hpa405',\n",
       " 'lh-rh',\n",
       " 'hsp90',\n",
       " 'chemoradioimmunotherapy',\n",
       " 'v600-e-b-raf',\n",
       " 'critical',\n",
       " 'chemohormonotherapy',\n",
       " 'mbd-',\n",
       " 'facilitation',\n",
       " 'non-surgery',\n",
       " 'pghs',\n",
       " 'hla-specific',\n",
       " 'cotransporter',\n",
       " 'tract',\n",
       " 'dexamethasone-inducible',\n",
       " 'urotherapy',\n",
       " 'programmed-death-1',\n",
       " 'methanol',\n",
       " 'rho-gdp',\n",
       " 'dc-based',\n",
       " 'post-kidney',\n",
       " 'ret-targeting',\n",
       " 'bafetinib',\n",
       " 'stop',\n",
       " 'asecond',\n",
       " 'calgb',\n",
       " 'tumour-destructive',\n",
       " 'war',\n",
       " 'intense',\n",
       " 'ranibicizumab',\n",
       " 'rastuzumab',\n",
       " 'haplo-identical',\n",
       " 'hance',\n",
       " 'network',\n",
       " 'glaucoma',\n",
       " 'treosulfan-based',\n",
       " 'swallow',\n",
       " 'allogeneic-hematopoietic',\n",
       " 'vaccination',\n",
       " 'r-il-2',\n",
       " 'methyl-triazolo',\n",
       " 'conditioning',\n",
       " 'guided',\n",
       " 'oatps',\n",
       " 'ala',\n",
       " 'cll',\n",
       " 'icd',\n",
       " 'ketoconazole',\n",
       " 'particle',\n",
       " 'high-quality',\n",
       " 'trypanocidal',\n",
       " 'con-',\n",
       " 'pnet',\n",
       " 'oatp1a',\n",
       " 'auto-corneal',\n",
       " 'dual-erbb',\n",
       " 'ro4929097',\n",
       " 'anti-leukaemia',\n",
       " 'gw572016',\n",
       " 'p-stat3',\n",
       " 'top-i-directed',\n",
       " 'vigorous',\n",
       " 'ifnb-1b',\n",
       " 'pi3-k-akt',\n",
       " 'radon',\n",
       " 'endolaser',\n",
       " 'vascular-directed',\n",
       " 'ckd-mbd',\n",
       " 'tendon',\n",
       " 'rho-associated',\n",
       " 'iall',\n",
       " 'sertraline',\n",
       " 'wt1-based',\n",
       " 'mzp3',\n",
       " 'crm1',\n",
       " 'diet',\n",
       " 'abthera',\n",
       " 'calmette-gu?rin',\n",
       " 'intend',\n",
       " 'megachoep',\n",
       " 'eribulin',\n",
       " 'lys-27',\n",
       " 'azathioprine-based',\n",
       " 'negligible',\n",
       " '-tyrosine',\n",
       " 'joint',\n",
       " 'histology-based',\n",
       " '-specific',\n",
       " 'ext',\n",
       " 'unmanipulated',\n",
       " 'lethality',\n",
       " 'motivational',\n",
       " 'risk-stratified',\n",
       " 'once-a-day',\n",
       " 'it',\n",
       " 'maraviroc',\n",
       " 'right',\n",
       " 'gm-csf-producing',\n",
       " 'c-src-specific',\n",
       " 'proteasome-inhibitor',\n",
       " 'non-teratogenic',\n",
       " 'cn-ii',\n",
       " 'indatuximab',\n",
       " 'parvovirus',\n",
       " 'multi-tyrosine',\n",
       " 'devacirepvec',\n",
       " 'soc',\n",
       " 'urgent',\n",
       " 'unmodified',\n",
       " 'vegfr',\n",
       " 'adjuvant-based',\n",
       " 'iii-iv',\n",
       " 'progestin',\n",
       " 'neoantigen-based',\n",
       " 'immunochemical',\n",
       " 'enoblituzumab',\n",
       " 'immunological',\n",
       " 'skin',\n",
       " 'aroa',\n",
       " 'objective',\n",
       " 'rhtsh-based',\n",
       " 'motivation',\n",
       " 'hormonel',\n",
       " 'es-based',\n",
       " 'mitomycin',\n",
       " 'chemoradiotherapy-cisplatin-based',\n",
       " 'blue-mediated',\n",
       " 'formononetin-combined',\n",
       " 'ototoxic',\n",
       " 'nano-core',\n",
       " 'chemordiotherapy',\n",
       " 'pre-alk',\n",
       " 'gm-csf-secreting',\n",
       " '27',\n",
       " 'ikappabalpha',\n",
       " 'prulifloxacin',\n",
       " 'gen-1',\n",
       " 'dutpase',\n",
       " 'desire',\n",
       " 'csf1',\n",
       " 'braf-targeted',\n",
       " 'cooperative',\n",
       " 'full-course',\n",
       " 'immunologically',\n",
       " 'anti-tnf-alpha',\n",
       " 'i-131',\n",
       " 'il-6',\n",
       " 'statistically',\n",
       " 'ifnalpha2a',\n",
       " 'proliferative',\n",
       " 'prostaglandin',\n",
       " 'failure-of',\n",
       " 'glucarpidase',\n",
       " 'imaging',\n",
       " 'immune-modulating',\n",
       " 'polatuzumab',\n",
       " 'future.molecular',\n",
       " 'baricitinib',\n",
       " 'vinflunine',\n",
       " 'candesartan',\n",
       " 'regorafenib',\n",
       " '1st',\n",
       " 'exemestane',\n",
       " 'antimitotic',\n",
       " 'multi-center',\n",
       " 'phenformin',\n",
       " 'ft-based',\n",
       " 'signaling-targeted',\n",
       " 'post-doxorubicin',\n",
       " 'mhc',\n",
       " 'mbl',\n",
       " 'anagrelide',\n",
       " 'detection',\n",
       " 'palo',\n",
       " 'easome',\n",
       " 'cox-independent',\n",
       " 'much',\n",
       " 'ca2+',\n",
       " 'long-course',\n",
       " 'cd8',\n",
       " 'quinolone-based',\n",
       " 'cross-protective',\n",
       " 'pegvisomant',\n",
       " 'response-directed',\n",
       " 'unconventional',\n",
       " 'alumtuzumab',\n",
       " 'cost-saving',\n",
       " 'benralizumab',\n",
       " 'rhuflt3l',\n",
       " 'treatment',\n",
       " 'photocoagulation',\n",
       " 'risperidone',\n",
       " 'grief',\n",
       " 'exist',\n",
       " 'mirror',\n",
       " 'salmonella-mediated',\n",
       " 'steroidotherapy',\n",
       " 'slightly',\n",
       " 'talazoparib',\n",
       " \"'endocrine\",\n",
       " 'jeb',\n",
       " 'pencil',\n",
       " 'cixutumumab',\n",
       " 'molecule-based',\n",
       " 'augmented',\n",
       " 'gy?androgen',\n",
       " '86',\n",
       " 'mv-cea',\n",
       " 'interleukin-6',\n",
       " 'cervarix',\n",
       " 'investigate',\n",
       " 'gold',\n",
       " 'narrative',\n",
       " 'feb',\n",
       " 'dermatotherapy',\n",
       " 'anti-ntm',\n",
       " 'abiraterone',\n",
       " 'camkii',\n",
       " 'pathology',\n",
       " 'gpc3',\n",
       " 'post-salvage',\n",
       " 'immunoactive',\n",
       " 'bontalc',\n",
       " 'herpesviral',\n",
       " 'ebrt-based',\n",
       " 'va',\n",
       " 'vd',\n",
       " 'biomarker-driven',\n",
       " 'indoleamine',\n",
       " 'caspase-12',\n",
       " 'anti-vegf',\n",
       " 'exosite',\n",
       " 'psoriasis',\n",
       " 'chemo-sirna',\n",
       " 'known',\n",
       " 'bfm',\n",
       " 'supplemental',\n",
       " 'rational',\n",
       " 'mpr',\n",
       " 'atherosclerotic',\n",
       " 'mono-drug',\n",
       " 'phgdh',\n",
       " 'nhlf',\n",
       " 'motherapy',\n",
       " 'bean',\n",
       " 'induced-nf-?b',\n",
       " 'widely',\n",
       " 'adecatumumab',\n",
       " 'gc7',\n",
       " 'subtenon',\n",
       " 'azd5363',\n",
       " 'cmv-promoter',\n",
       " 'onartuzumab',\n",
       " 'domain-like',\n",
       " 'atp-uncompetitive',\n",
       " 'vadastuximab',\n",
       " 'vlp',\n",
       " 'pank3',\n",
       " 'interleukin-15',\n",
       " 'nv1020',\n",
       " 'rher-2',\n",
       " 'logical',\n",
       " 'jak1',\n",
       " 'maoa',\n",
       " 'anti-leishmanial',\n",
       " 'post-ki',\n",
       " 'fractionate',\n",
       " 'neoajuvant',\n",
       " 'adenosine',\n",
       " 'anti-ctla4-hsc',\n",
       " 'artificial',\n",
       " 'etn-mtx',\n",
       " 'cyclooxygenase-2',\n",
       " 'el',\n",
       " 'personalized',\n",
       " 'mark',\n",
       " 'en',\n",
       " 'rituximab',\n",
       " 'reduced-fluence',\n",
       " 'abcb1',\n",
       " 'poly-adp-ribose',\n",
       " 'mir-21-5p',\n",
       " 'ly294002',\n",
       " 'next',\n",
       " 'perk1',\n",
       " 'trail-based',\n",
       " '-free',\n",
       " 'ltcc',\n",
       " 'assay-directed',\n",
       " 'perjeta',\n",
       " 'needle-free',\n",
       " '01',\n",
       " 'givinostat',\n",
       " 'anti-latency',\n",
       " 'depression',\n",
       " 'tenofovir',\n",
       " 'combination',\n",
       " 'l19-tnf',\n",
       " 'arg',\n",
       " 'gdc-0810',\n",
       " 'thrombocyte',\n",
       " 'dcs-dribbles',\n",
       " 'anti-cd33',\n",
       " 'verteporfin-based',\n",
       " 'cornerstone',\n",
       " 'nolvadex',\n",
       " 'pan-bcl-2',\n",
       " 'cyclophosphamide-using',\n",
       " 'oestrogen',\n",
       " 'pbo',\n",
       " 'neurosurgical',\n",
       " 'parp1-targeted',\n",
       " 'dc1-based',\n",
       " 'cd34+',\n",
       " 'hla-identical',\n",
       " 'nmt',\n",
       " 'ultrasonic',\n",
       " 'dcher2',\n",
       " 'gate',\n",
       " 'hnf4?',\n",
       " 'adoptive',\n",
       " 'anti-her-2',\n",
       " 'anti-epidermal',\n",
       " 'nanoparticle-enabled',\n",
       " 'flice',\n",
       " 'cell-depleting',\n",
       " 'autoplasmachemotherapy',\n",
       " 'komplikation',\n",
       " 'cyclin-cdk',\n",
       " 'immunoablative',\n",
       " 'mtorc?mer',\n",
       " 'patritumab',\n",
       " 'fix',\n",
       " 'nhe',\n",
       " 'ex',\n",
       " 'partial',\n",
       " 'cni-based',\n",
       " 'bd',\n",
       " 'revolutionary',\n",
       " '???i',\n",
       " 'garment',\n",
       " 'hypodermic',\n",
       " 'acoustic',\n",
       " 'upf1',\n",
       " 'initial',\n",
       " 'once-weekly',\n",
       " 'hil-10',\n",
       " 'immunomodulant',\n",
       " 'bcr-abl+',\n",
       " 'antimalignant',\n",
       " 'femoral',\n",
       " 'arsenic',\n",
       " 'prominent',\n",
       " 'lucitanib',\n",
       " 'mbi',\n",
       " 'caspase-4',\n",
       " 'nfat',\n",
       " 'azd5069',\n",
       " 'pi-3-kinase',\n",
       " 'olanzapine',\n",
       " 'soft',\n",
       " 'jaki',\n",
       " 'wee-1',\n",
       " 'rho',\n",
       " 'zinecard',\n",
       " 'aggressive',\n",
       " 'phosphorylate',\n",
       " 'all-trans',\n",
       " 'disparate',\n",
       " 'healthy',\n",
       " 'viral-directed',\n",
       " '19s',\n",
       " 'alk-tyrosine',\n",
       " 'cortico-steroid',\n",
       " 'pittsburgh',\n",
       " 'gamma-secretase',\n",
       " 'thermoradiotherapy',\n",
       " 'ebrt',\n",
       " 'alemtuzumab-based',\n",
       " 'cns-directed',\n",
       " 'largely',\n",
       " 'scchn',\n",
       " 'pulse',\n",
       " 'antiandrogen',\n",
       " 'ld',\n",
       " 'interleukin-17',\n",
       " 'adenovirus-mediated',\n",
       " 'dnapk',\n",
       " 'ultra-brief',\n",
       " 'mic',\n",
       " 'polymer',\n",
       " 'mor03087',\n",
       " 'scar',\n",
       " 'as03a-adjuvanted',\n",
       " 'chronocheotherapy',\n",
       " 'purify',\n",
       " 'nos',\n",
       " 'measles',\n",
       " 'chemo-external',\n",
       " 'non-genotoxic',\n",
       " 'hl',\n",
       " 'insufficient',\n",
       " 'tincr',\n",
       " \"'in\",\n",
       " 'plgf',\n",
       " 'nsc',\n",
       " 'cd19-car',\n",
       " 'completely',\n",
       " '11?-hsd1',\n",
       " 'ehf',\n",
       " 'tumour-tailored',\n",
       " 'pi3-kinase',\n",
       " 'intercurrent',\n",
       " 'raas',\n",
       " 'melatonin',\n",
       " 'pelareorep',\n",
       " 'serotonin-norepinephrine',\n",
       " 'new-tnf?',\n",
       " 'pathogenesis-oriented',\n",
       " 'catumaxomab',\n",
       " 'full-arc',\n",
       " 'rhoa',\n",
       " 'aad',\n",
       " 'lipid',\n",
       " 'sa-mgm-csf',\n",
       " 'nanomolar',\n",
       " 'progression.aromatase',\n",
       " 'br',\n",
       " 'orally',\n",
       " 'multiple-targeted',\n",
       " 'concentration-dependent',\n",
       " 'pdgfralpha',\n",
       " 'double-combination',\n",
       " 'ofloxacin',\n",
       " 'magnetolaserotherapy',\n",
       " 'tin',\n",
       " 'inhibidor',\n",
       " 'olaparib',\n",
       " 'csdmard',\n",
       " 'lysate-pulsed',\n",
       " 'pkc-delta-selective',\n",
       " 'offer',\n",
       " 'anti-idiotypic',\n",
       " 'dcova-p30',\n",
       " 'busulfan-treated',\n",
       " 'erbb',\n",
       " 'osteoclast-targeting',\n",
       " 'evolocumab',\n",
       " 'jak2-specific',\n",
       " 'scd1',\n",
       " 'adjuvent',\n",
       " 'qhpv',\n",
       " 'polytherapy',\n",
       " 'antibiotic',\n",
       " 'institute',\n",
       " 'fty720',\n",
       " 'valrubicin',\n",
       " 'immunoparalysis',\n",
       " '-182',\n",
       " 'nodal',\n",
       " 'primate',\n",
       " 'combine',\n",
       " 'tanezumab',\n",
       " 'non-cancer-related',\n",
       " 'permeant',\n",
       " 'observe',\n",
       " 'defibrotide',\n",
       " 'dex',\n",
       " 'egf',\n",
       " 'cd30-directed',\n",
       " 'pan-deacetylase',\n",
       " 'wnt',\n",
       " 'multiepitope',\n",
       " 'kgf',\n",
       " 'relative',\n",
       " 'angiotensin',\n",
       " 'rcc',\n",
       " 'thermally',\n",
       " 'real-life',\n",
       " 'anti?angiogenic',\n",
       " 'significant',\n",
       " 'peg-intron',\n",
       " 'oligometastasis-directed',\n",
       " 'hemodialysis',\n",
       " 'plicamycin',\n",
       " 'splenectomy',\n",
       " 'osimertinib',\n",
       " 'neuraminidase',\n",
       " 'ndv',\n",
       " 'albumin-bound',\n",
       " 'preradiochemotherapy',\n",
       " 'pp1?',\n",
       " 'nhe1',\n",
       " 'induction',\n",
       " 'ldc',\n",
       " 'androgen-induced',\n",
       " 'bone-marrow',\n",
       " 'hyperfractionate',\n",
       " 'nk',\n",
       " 'anti-plasmodium',\n",
       " 'everolimu',\n",
       " 'mmp-3',\n",
       " 'pipobroman',\n",
       " 'thiotepa',\n",
       " 'hematopoieetic',\n",
       " 'her-family',\n",
       " 'bkm120',\n",
       " 'non-recombinant',\n",
       " 'cytoxan',\n",
       " 'hmg-coa',\n",
       " 'post-liver',\n",
       " 'novel-generation',\n",
       " 'tivantinib',\n",
       " 'nf-kappab-specific',\n",
       " 'use',\n",
       " 'cimavax-egf',\n",
       " 'anti-ebv',\n",
       " 'die',\n",
       " 'anti-thymocyte',\n",
       " 'nanoparticle-aided',\n",
       " 'idelalisib',\n",
       " 'overlap',\n",
       " 'individually',\n",
       " 'electrical',\n",
       " '2,3-dioxygenase',\n",
       " 'cycled',\n",
       " 'glycopeptide',\n",
       " 'caprelsa',\n",
       " 'p38alpha',\n",
       " 'colony-stimulating',\n",
       " 'r-2-cda',\n",
       " 'cmc-544',\n",
       " 'gp130',\n",
       " 'global',\n",
       " 'regn2810',\n",
       " 'fms-like',\n",
       " 'antibacterial',\n",
       " '24?',\n",
       " 'gd2-specific',\n",
       " 'docetaxel',\n",
       " 'afterloade',\n",
       " 'tumor-targeted',\n",
       " 'translational',\n",
       " 'pathophysiology',\n",
       " '?-hydroxylase',\n",
       " 'mri-based',\n",
       " 'stimulus',\n",
       " 'high-pressure-oxygen',\n",
       " 'multi-gene',\n",
       " 'aurkb-selective',\n",
       " 'vinorelbine-based',\n",
       " 'in-breast',\n",
       " 'event',\n",
       " 'antithymocyte',\n",
       " 'cerebral',\n",
       " 'first-cycle',\n",
       " 'endostar',\n",
       " 'testis-conserving',\n",
       " 'iii',\n",
       " 'step',\n",
       " 'rosacea',\n",
       " 'gantenerumab',\n",
       " 'deceased-donor',\n",
       " 'ryr',\n",
       " 'exhibit',\n",
       " 'vit',\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf = extract_drugs(data)\n",
    "known_drugs = set(buf)\n",
    "known_drugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что очень много странных меток. Посмотрим на частотность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('therapy', 61913), ('chemotherapy', 60890), ('radiotherapy', 26939), ('inhibitor', 20611), ('cisplatin', 12169), ('bevacizumab', 8995), ('dexamethasone', 8328), ('transplantation', 7956), ('paclitaxel', 7583), ('calcium', 6545), ('docetaxel', 6446), ('rituximab', 6365), ('il-10', 6242), ('gemcitabine', 6023), ('doxorubicin', 5877), ('5', 5314), ('fu', 4989), ('radiation', 4850), ('cyclophosphamide', 4795), ('curcumin', 4571), ('monotherapy', 4550), ('immunotherapy', 4515), ('imatinib', 4514), ('methotrexate', 4509), ('tamoxifen', 4385), ('sorafenib', 4363), ('brachytherapy', 4153), ('fluorouracil', 4151), ('carboplatin', 4070), ('chemoradiotherapy', 3909), ('trastuzumab', 3803), ('vaccine', 3613), ('prednisone', 3383), ('erlotinib', 3330), ('capecitabine', 3301), ('oxaliplatin', 3295), ('metformin', 3245), ('ranibizumab', 3204), ('everolimus', 3063), ('cetuximab', 3015), ('cell', 2969), ('irinotecan', 2959), ('bortezomib', 2955), ('sunitinib', 2943), ('and', 2884), ('kinase', 2876), ('combination', 2758), ('s-1', 2526), ('inhibitory', 2496), ('gefitinib', 2390)]\n"
     ]
    }
   ],
   "source": [
    "print (Counter(buf).most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать, что это ошибки и в будущем подумаем как с ними работать. Можно попытаться выкинуть самые частотные ошибки вручную, но для постановки бейслайна это не нужно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общее количество слов - 25318985\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи.\n",
    "Будем пытаться симулировать реальную проблему, а именно: на вход поступают тексты, а мы ищем в них названия препаратов. Таким образом получаем задачу бинарной классификации слов.   \n",
    "В качестве метрики выберем f1 score, т.к. размеры классов 'название препарата' - 'обычное слово' сильно несбалансированы.\n",
    "В последующем работать будем с делением по предложениям.  \n",
    "Начнем с решения \"в лоб\".\n",
    "Составим множество всех названий препаратов. Не будем делать поправку на то, сколько раз слово встречается в исходных данных. \n",
    "Лематизацию и удаление стоп слов проводить не будем, для ускорения обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test = sklearn.model_selection.train_test_split(data, test_size=0.3, random_state=0)\n",
    "data_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Долго.\n",
    "Вычисляем количество слов в тестовой и тренировочной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = word_counter(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9947779"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9947779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4272307"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num = word_counter(data_test)\n",
    "test_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4272307"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразовываем исходные данные в более удобные для обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data_train = create_data(data_train, 9947779)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentence</th>\n",
       "      <th>drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9947769</th>\n",
       "      <td>second</td>\n",
       "      <td>69999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947770</th>\n",
       "      <td>disease</td>\n",
       "      <td>69999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947771</th>\n",
       "      <td>into</td>\n",
       "      <td>69999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947772</th>\n",
       "      <td>remission</td>\n",
       "      <td>69999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947773</th>\n",
       "      <td>suddenly</td>\n",
       "      <td>69999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947774</th>\n",
       "      <td>sepsis</td>\n",
       "      <td>69999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947775</th>\n",
       "      <td>after</td>\n",
       "      <td>69999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947776</th>\n",
       "      <td>fourth</td>\n",
       "      <td>69999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947777</th>\n",
       "      <td>chemotherapy</td>\n",
       "      <td>69999</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947778</th>\n",
       "      <td>cycle</td>\n",
       "      <td>69999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word  sentence   drug\n",
       "9947769        second     69999  False\n",
       "9947770       disease     69999  False\n",
       "9947771          into     69999  False\n",
       "9947772     remission     69999  False\n",
       "9947773      suddenly     69999  False\n",
       "9947774        sepsis     69999  False\n",
       "9947775         after     69999  False\n",
       "9947776        fourth     69999  False\n",
       "9947777  chemotherapy     69999   True\n",
       "9947778         cycle     69999  False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_data_train.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data_test = create_data(data_test, 5313143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def My_predictor(data_train, data_test):\n",
    "    drug_set = set(data_train.word.values[data_train.drug.values])\n",
    "    y_pred = np.zeros((data_test.shape[0]))\n",
    "    for i, row in enumerate(data_test.values):\n",
    "        if (not drug_set.isdisjoint(set([row[0]]))):\n",
    "            y_pred[i] = 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = My_predictor(transform_data_train, transform_data_test[['word', 'sentence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.53      0.69   5108258\n",
      "        True       0.08      0.98      0.14    204885\n",
      "\n",
      "   micro avg       0.55      0.55      0.55   5313143\n",
      "   macro avg       0.54      0.75      0.42   5313143\n",
      "weighted avg       0.96      0.55      0.67   5313143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_true=transform_data_test.drug.values, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемо видим маленький precision и большой recall.  \n",
    "Можно попытаться улучшить модель - проведя OneHotEncoding и обучив на этих словах какую-нибудь линейную модель. Это позволит хорошо предсказывать известные названия препаратов, которые встречаются часто, но будет очень плохо работать с новыми, потому что вектор признаков таких слов будет состоять из одних нулей. \n",
    "Попробуем построить такую модель, а затем начнем добавлять признаки, что позволит модели начать находить неизвестные ей названия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_hot = encoder.fit_transform(transform_data_train['word'].values.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_one_hot = encoder.transform(transform_data_test['word'].values.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nariman/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "log_reg = sklearn.linear_model.LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(train_one_hot, transform_data_train['drug'].values * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('Classifier.model', 'wb')\n",
    "_pickle.dump(log_reg, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98   5108258\n",
      "           1       0.45      0.91      0.60    204885\n",
      "\n",
      "   micro avg       0.95      0.95      0.95   5313143\n",
      "   macro avg       0.72      0.93      0.79   5313143\n",
      "weighted avg       0.97      0.95      0.96   5313143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_pred=log_reg.predict(test_one_hot), y_true=transform_data_test['drug'].values * 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметное улучшение, как и предсказывалось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastText\n",
    "Теперь воспользуемся fasttext. Использование н-грам должно позволить нам выявлять не только особенности контекста названий препаратов, но и общее строение их названий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = []\n",
    "for row in data_train:\n",
    "    for i in re.split(' \\. ', row[1]):\n",
    "        train_sentences.append(my_tokenizer(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(train_sentences, size = 200, window = 5, min_count = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('FastText.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText.load('FastText.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не выходит обработать все файлы за один подход - фасттекст занимает много памяти. Будем делать это частями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_for_FT = create_data_for_FT(data_train, 9947779)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_for_FT = create_data_for_FT(data_test, 4272307)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала с вектором признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(i)\n",
    "    data_train_for_FT_part = data_train_for_FT[99477*i:99477*(i+1)]\n",
    "    for_dump = np.empty((99477, 200))\n",
    "    for count, word in enumerate(data_train_for_FT_part.word):\n",
    "        for_dump[count] = model.wv[word]\n",
    "    file = open('FF_emb_train'+str(i)+'.dat', 'wb')\n",
    "    _pickle.dump(for_dump, file)\n",
    "    file.close()\n",
    "data_train_for_FT_part = data_train_for_FT[9947700:]\n",
    "for_dump = np.empty((79, 200))\n",
    "for i, word in enumerate(data_train_for_FT_part.word):\n",
    "    for_dump[i] = model.wv[word]\n",
    "file = open('FF_emb_train'+str(100)+'.dat', 'wb')\n",
    "_pickle.dump(for_dump, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print (i)\n",
    "    data_test_for_FT_part = data_test_for_FT[42723*i:42723*(i+1)]\n",
    "    for_dump = np.empty((42723, 200))\n",
    "    for count, word in enumerate(data_test_for_FT_part.word):\n",
    "        for_dump[count] = model.wv[word]\n",
    "    file = open('FF_emb_test'+str(i)+'.dat', 'wb')\n",
    "    _pickle.dump(for_dump, file)\n",
    "    file.close()\n",
    "data_test_for_FT_part = data_test_for_FT[4272300:]\n",
    "for_dump = np.empty((7, 200))\n",
    "for i, word in enumerate(data_test_for_FT_part.word):\n",
    "    for_dump[i] = model.wv[word]\n",
    "file = open('FF_emb_test'+str(100)+'.dat', 'wb')\n",
    "_pickle.dump(for_dump, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь и меток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train_for_FT.drug.values*1\n",
    "y_test  = data_test_for_FT.drug.values*1[:42723*29]\n",
    "file = open('y_train.txt', 'wb')\n",
    "_pickle.dump(y_train, file)\n",
    "file.close()\n",
    "file = open('y_test.txt', 'wb')\n",
    "_pickle.dump(y_test, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X_train = np.empty((0,200))\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    file = open ('FF_emb_train'+str(i)+'.dat', 'rb')\n",
    "    adder = _pickle.load(file)\n",
    "    X_train = np.vstack((X_train, adder))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('X_train_0_10.dat', 'wb')\n",
    "_pickle.dump(X_train, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('X_train_0_10.dat', 'rb')\n",
    "X_train = _pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('y_train.txt', 'rb')\n",
    "y_train = (_pickle.load(file))[:994770]\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nariman/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=4, penalty='l2', random_state=None,\n",
       "          solver='saga', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = LogisticRegression(class_weight='balanced', solver='saga', n_jobs=4)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('LogReg_FT.model', 'wb')\n",
    "_pickle.dump(LogReg, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('LogReg_FT.model', 'rb')\n",
    "LogReg = _pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X_test = np.empty((0,200))\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    file = open ('FF_emb_test'+str(i)+'.dat', 'rb')\n",
    "    adder = _pickle.load(file)\n",
    "    X_test = np.vstack((X_test, adder))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('y_test.txt', 'rb')\n",
    "y_test = (_pickle.load(file))[:427230]\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96    406751\n",
      "           1       0.36      0.88      0.52     20479\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    427230\n",
      "   macro avg       0.68      0.90      0.74    427230\n",
      "weighted avg       0.96      0.92      0.94    427230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_pred=LogReg.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разумеется нехорошо мерить тот же скор на меньших выборках, но у нас нет выбора.\n",
    "Попробуем обучить еще один классификатор на других данных и замиксить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('LogReg_FT_1.model', 'wb')\n",
    "_pickle.dump(LogReg, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('LogReg_FT.model', 'rb')\n",
    "model_1 = _pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.predict(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X_train = np.empty((0,200))\n",
    "for i in range(10, 20):\n",
    "    print(i-10)\n",
    "    file = open ('FF_emb_train'+str(i)+'.dat', 'rb')\n",
    "    adder = _pickle.load(file)\n",
    "    X_train = np.vstack((X_train, adder))\n",
    "    file.close()\n",
    "    \n",
    "file = open('X_train_10_20.dat', 'wb')\n",
    "_pickle.dump(X_train, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('X_train_10_20.dat', 'rb')\n",
    "X_train = _pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('y_train.txt', 'rb')\n",
    "y_train = (_pickle.load(file))[994770:1989540]\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nariman/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "LogReg_2 = LogisticRegression(class_weight='balanced', solver='saga', n_jobs=4)\n",
    "LogReg_2.fit(X_train, y_train)\n",
    "file = open('LogReg_FT_2.model', 'wb')\n",
    "_pickle.dump(LogReg_2, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('LogReg_FT_2.model', 'rb')\n",
    "model_2 = _pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('LogReg_FT.model', 'rb')\n",
    "model_1 = _pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('LogReg_FT_1.model', 'wb')\n",
    "_pickle.dump(model_1,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "X_test = np.empty((0,200))\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    file = open ('FF_emb_test'+str(i)+'.dat', 'rb')\n",
    "    adder = _pickle.load(file)\n",
    "    X_test = np.vstack((X_test, adder))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(854460, 200)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('y_test.txt', 'rb')\n",
    "y_test = (_pickle.load(file))[:854460]\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96    813593\n",
      "           1       0.36      0.88      0.51     40867\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    854460\n",
      "   macro avg       0.68      0.90      0.74    854460\n",
      "weighted avg       0.96      0.92      0.94    854460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_pred=model_2.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95    813593\n",
      "           1       0.34      0.89      0.50     40867\n",
      "\n",
      "   micro avg       0.91      0.91      0.91    854460\n",
      "   macro avg       0.67      0.90      0.72    854460\n",
      "weighted avg       0.96      0.91      0.93    854460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_pred=[(x[0]+x[1] > 0)*1 for x in zip(model_1.predict(X_test), model_2.predict(X_test))], y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не получилось. А может деревом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=15, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=40, n_jobs=4, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees = RandomForestClassifier(n_estimators=40, max_depth=15, n_jobs=4, class_weight='balanced')\n",
    "trees.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97    813593\n",
      "           1       0.44      0.89      0.59     40867\n",
      "\n",
      "   micro avg       0.94      0.94      0.94    854460\n",
      "   macro avg       0.72      0.92      0.78    854460\n",
      "weighted avg       0.97      0.94      0.95    854460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_pred=trees.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('Random_Forest_FT_1.model', 'wb')\n",
    "_pickle.dump(trees,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('X_train_10_20.dat', 'rb')\n",
    "X_train = _pickle.load(file)\n",
    "file.close()\n",
    "file = open('y_train.txt', 'rb')\n",
    "y_train = (_pickle.load(file))[994770:1989540]\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=15, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=40, n_jobs=4, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_2 = RandomForestClassifier(n_estimators=40, max_depth=15, n_jobs=4, class_weight='balanced')\n",
    "trees_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('Random_Forest_FT_2.model', 'wb')\n",
    "_pickle.dump(trees_2,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('Random_Forest_FT_1.model', 'rb')\n",
    "trees_1 = _pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    813593\n",
      "           1       0.39      0.91      0.54     40867\n",
      "\n",
      "   micro avg       0.93      0.93      0.93    854460\n",
      "   macro avg       0.69      0.92      0.75    854460\n",
      "weighted avg       0.97      0.93      0.94    854460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_pred=[(x[0]+x[1] > 0)*1 for x in zip(trees_1.predict(X_test), trees_2.predict(X_test))], y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну что ж, будем пользоваться бейслайном."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итог: воспользуемся второй моделью, обученной на всех словах, сохраним энкодер и саму модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что хочется сделать:  \n",
    "1. Улучшить предобработку слов. Вставить лематизацию и нормальное удаление стоп-слов.  \n",
    "2. Добавить фичей получше. К примеру очень хочется использовать контекст: предыдущее и последующее слова. Так мы сможем обнаруживать названия препаратов, которые очень сильно не похожи на остальные(возможно название бренда).\n",
    "3. Использовать все данные. В данный момент, даже 30% трейна занимают почти 4гб в пикле, а есть еще тест, который в 2 раза меньше. Как это можно сделать: уменьшить размер эмбединга фасттекста, использовать больше оперативной памяти, либо же использовать смесь моделей, обученных на разных частях данных, желательно сильно пересекающихся.\n",
    "Можно подумать, что применить стандартные методы понижения размерности (PCA, SVD и тд) - неплохая идея, но на NLP они, как правило, не работают."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
